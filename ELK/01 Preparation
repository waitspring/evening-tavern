 , __                                                     
/|/  \                                    o               
 |___/ ,_    _    _   __,   ,_    __, _|_     __   _  _   
 |    /  |  |/  |/ \_/  |  /  |  /  |  |  |  /  \_/ |/ |  
 |       |_/|__/|__/ \_/|_/   |_/\_/|_/|_/|_/\__/   |  |_/
               /|                                         
               \|                                                                                                         
--  This document was created by Xuanming in 2022, thanks for your reading



━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
ELK 项目的发展历程
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
ELK 项目当前由弹性搜索公司 (Elastic Stack) 负责迭代与维护, 已是互联网生态中最常见的日志数据处理项目
ELK 项目能够把一条业务日志数据封装为一个消息事件, 消息事件内部封装有 "@version"/ "@timestamp" 在内的 ELK 项目元数据
ELK 项目下辖 Elasticsearch (E)/ Logstash (L)/ Kibana (K)/ Filebeat 四款不同软件:

    •  Elasticsearch  --  最初由伦敦的开源工程师班农 (Shay Banon) 发布, 负责搜索分析日志数据, 为保证数据安全, 通常使用集群模式部署
    •  Logstash       --  最初由旧金山的开源工程师西塞 (Jordan Sissel) 发布, 负责汇总过滤日志数据
    •  Kibana         --  最初由凤凰城的开源工程师可汗 (Rashid Khan) 发布, 基于 WEB 工具提供日志数据的可视化服务
    •  Filebeat       --  负责采集日志数据, 本身是弹性搜索公司 Beats 项目的一员

ELK 项目的发展历程清晰简单
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
**  2004 年, 班农使用 Java 语言编写出 Compass 软件 (基于 Apache Lucene 的源码二次开发得到的结果)
**  2009 年, 西塞使用 Ruby 语言编写出 Logstash 软件
**  2010 年, 班农使用 Java 语言编写出 Elasticsearch 软件 (基于 Compass 的源码二次开发得到的结果)
**  2012 年, 可汗使用 TypeScript 语言编写出 Kibana 软件
**  2013 年, Elasticsearch/ Logstash/ Kibana 三款软件的作者携手创业, 创立弹性搜索公司
**  2015 年, 弹性搜索公司与亚马逊云 (AWS) 合作, 推出 SaaS 服务
**  2016 年, 弹性搜索公司筹建 Beats 项目, 涵盖 Filebeat/ Packetbeat/ Metricbeat/ Auditbeat/ Winlogbeat/ Heartbeat/ ...
**  2018 年, 弹性搜索公司在纽交所 (NYSE) 上市, 使用 ESTC 作为股票代码

ELK 项目的版本编号在早期较混乱, 其主要表现在于下辖软件的版本编号和发版计划不一致, 但自 2016 年起这一问题已得到较大改善
┌────────────┬──────────┬─────────────────────────────────────────────────────────────────────────────────────────────┐
│            │          │ • Elasticsearch upgrade to Lucene 6.x                                                       │
│ 2016-10-27 │ 5.0.0    │ • Kibana upgrade to NodeJS 6.x                                                              │
│            │          │ • ELK support Java API                                                                      │
├────────────┼──────────┼─────────────────────────────────────────────────────────────────────────────────────────────┤
│            │          │ • Elasticsearch upgrade to Lucene 7.x                                                       │
│ 2017-11-15 │ 6.0.0    │ • Kibana upgrade to NodeJS 8.x                                                              │
│            │          │ • ELK support for running multiple pipelines in the same Logstash instance                  │
├────────────┼──────────┼─────────────────────────────────────────────────────────────────────────────────────────────┤
│            │          │ • Elasticsearch upgrade to Lucene 8.x                                                       │
│ 2019-04-11 │ 7.0.0    │ • Kibana upgrade to NodeJS 10.x                                                             │
│            │          │ • Kibana use a new UI theme                                                                 │
├────────────┼──────────┼─────────────────────────────────────────────────────────────────────────────────────────────┤
│            │          │ • Elasticsearch upgrade to Lucene 9.x                                                       │
│ 2022-02-11 │ 8.0.0    │ • Kibana support models to bring NLP use cases to the Elastic Stack                         │
│            │          │ • Logstash support UTF-16 and other multi-byte-character when reading log files             │
└────────────┴──────────┴─────────────────────────────────────────────────────────────────────────────────────────────┘

ELK 项目的官方网站与 GitHub 第三方开源社区, 清华大学开源软件镜像站等都提供相应软件的下载服务
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
当前文档的演示案例统一使用 ELK 6.8.23 版本, 其下载地址为 https://artifacts.elastic.co:

    •  Elasticsearch                             [               .../downloads/elasticsearch/elasticsearch-6.8.23.rpm ]
    •  Logstash                                  [                         .../downloads/logstash/logstash-6.8.23.rpm ]
    •  Kibana                                    [                      .../downloads/kibana/kibana-6.8.23-x86_64.rpm ]
    •  Filebeat                                  [            .../downloads/beats/filebeat/filebeat-6.8.23-x86_64.rpm ]
    •  ZooKeeper                                 [                                 https://kafka.apache.org/downloads ]
    •  Kafka                                     [                         https://zookeeper.apache.org/releases.html ]



━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
ELK 项目的主机配置
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
ELK 项目对主机配置有明确要求, 详细可参考官网文档 (https://www.elastic.co/guide/cn)
ELK 项目在本文档的演示案例中, 统一使用下述配置:

    ┌──────────────────────────────┬───────────────────┬───────────────────┬───────────────────┬──────────────────┐
    │                              │      CPU (C)      │    Memory (GB)    │     Disk (GB)     │      Number      │
    ├──────────────────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────────────┤
    │ Elasticsearch                │         4         │         8         │        500        │        3         │
    ├──────────────────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────────────┤
    │ Logstash                     │         4         │         8         │        100        │        1         │
    ├──────────────────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────────────┤
    │ Kibana                       │         2         │         4         │        100        │        1         │
    ├──────────────────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────────────┤
    │ Kafka                        │         2         │         4         │        100        │        3         │
    ├──────────────────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────────────┤
    │ ZooKeeper                    │         2         │         4         │        100        │        3         │
    ├──────────────────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────────────┤
    │ Filebeat                     │                   │                   │                   │        *         │
    └──────────────────────────────┴───────────────────┴───────────────────┴───────────────────┴──────────────────┘

ELK 项目的拓扑图展示如下
┌─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│                                                                                                                     │
│    ┌────────────────────┐          ┌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┐                      ┌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┐                   │
│    │ Host: A (Filebeat) ├╌╌╌╌┐     ┊ ┌──────────┐ ┊                      ┊ ┌──────────────────┐ ┊                   │
│    └────────────────────┘    ┊     ┊ │ Kafka: 0 │ ┊                      ┊ │ Elasticsearch: 0 │ ┊                   │
│                              ┊     ┊ └──────────┘ ┊                      ┊ └──────────────────┘ ┊                   │
│    ┌────────────────────┐    ┊     ┊ ┌──────────┐ ┊     ┌──────────┐     ┊ ┌──────────────────┐ ┊     ┌────────┐    │
│    │ Host: B (Filebeat) ├╌╌╌╌┼╌╌╌╌>┊ │ Kafka: 1 │ ┊<╌╌╌╌┤ Logstash ├╌╌╌╌>┊ │ Elasticsearch: 1 │ ┊<╌╌╌╌┤ Kibana │    │
│    └────────────────────┘    ┊     ┊ └──────────┘ ┊     └──────────┘     ┊ └──────────────────┘ ┊     └────────┘    │
│                              ┊     ┊ ┌──────────┐ ┊                      ┊ ┌──────────────────┐ ┊                   │
│    ┌────────────────────┐    ┊     ┊ │ Kafka: 2 │ ┊                      ┊ │ Elasticsearch: 2 │ ┊                   │
│    │ Host: C (Filebeat) ├╌╌╌╌┘     ┊ └──────────┘ ┊                      ┊ └──────────────────┘ ┊                   │
│    └────────────────────┘          └╌╌╌╌╌╌┬╌╌╌╌╌╌╌┘                      └╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┘                   │
│                                           ┊                              ┌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┐                   │
│                                           ┊                              ┊ ┌──────────────────┐ ┊                   │
│                                           ┊                              ┊ │   ZooKeeper: 0   │ ┊                   │
│                                           ┊                              ┊ └──────────────────┘ ┊                   │
│                                           ┊                              ┊ ┌──────────────────┐ ┊                   │
│                                           └╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌>┊ │   ZooKeeper: 1   │ ┊                   │
│                                                                          ┊ └──────────────────┘ ┊                   │
│                                                                          ┊ ┌──────────────────┐ ┊                   │
│                                                                          ┊ │   ZooKeeper: 2   │ ┊                   │
│                                                                          ┊ └──────────────────┘ ┊                   │
│                                                                          └╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┘                   │
│                                                                                                                     │
└─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘

ELK 项目受主机的内核参数的影响, 这些内核参数登记在下述配置文件:

    •  资源限制文件 /etc/security/limits.conf
    •  资源限制文件 /etc/security/limits.d/20-nproc.conf (优先级高于 /etc/security/limits.conf 资源限制文件)
    •  内核参数文件 /etc/sysctl.conf

资源限制文件 /etc/security/limits.conf
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*  soft  nofile  65535                           # 任意用户允许打开的文件句柄数量 (若触发阈值则告警)
*  hard  nofile  65535                           # 任意用户允许打开的文件句柄数量 (若触发阈值则不允许创建新的文件句柄)
*  soft  nproc   65535                           # 任意用户允许打开的进程数量 (若触发阈值则告警)
*  hard  nproc   65535                           # 任意用户允许打开的进程数量 (若触发阈值则不允许创建新的进程)
*  soft  stack   65535                           # 内存栈的容量上限, 容量单位 KB (若触发阈值则告警)
*  hard  stack   65535                           # 内存栈的容量上限, 容量单位 KB (若触发阈值则不允许继续扩大内存栈的容量)
*  soft  memlock unlimited                       # 允许用户锁定内存资源, 被锁定的内存资源不设置容量上限
*  hard  memlock unlimited                       # 允许用户锁定内存资源, 被锁定的内存资源不设置容量上限
*  soft  core    -1                              # 不设 coredump 文件的容量上限, 容量单位 KB
*  hard  core    -1                              # 不设 coredump 文件的容量上限, 容量单位 KB
*  soft  rss     -1
*  hard  rss     -1

内核参数文件 /etc/sysctl.conf
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
fs.file-max = 65535                              # 单个进程允许打开的文件句柄数量
net.ipv4.tcp_tw_reuse = 1                        # 新的连接允许复用 TIME_WAIT 状态下的套接字 (缩短套接字的释放时间)
net.ipv4.tcp_keepalive_time = 600                # 会话保持的探测频率为 600 秒
net.ipv4.tcp_fin_timeout = 30                    # 套接字保持 FIN_WAIT2 状态的时间上限为 30 秒
net.ipv4.tcp_max_tw_buckets = 5000               # 套接字保持 TIME_WAIT 状态的数量上限为 5000 个套接字 (多余套接字直接被清理)
net.ipv4.tcp_syncookies = 1                      # 避免主机遭受 TCP 连接的 SYN 攻击
net.ipv4.tcp_max_syn_backlog = 4096              # 配置连接的 SYN 请求队列的长度为 4096 (避免主机丢失客户端的连接请求)
net.ipv4.tcp_rmem = 4096 32768 262142            # 配置连接的接收缓存的最小值/ 默认值/ 最大值 (单位: 字节)
net.ipv4.tcp_wmem = 4096 32768 262142            # 配置连接的发送缓存的最小值/ 默认值/ 最大值 (单位: 字节)
net.ipv4.ip_local_port_range = 1024 65535        # 配置连接的本地端口的取值范围
net.core.netdev_max_backlog = 8096               # 配置连接的冗余接收队列的长度为 8096 个请求
net.core.rmem_default = 262144                   # 套接字的接收缓存区的默认容量为 262144 个字节
net.core.wmem_default = 262144                   # 套接字的发送缓存区的默认容量为 262144 个字节
net.core.rmem_max = 2097152                      # 套接字的接收缓存区的最大容量为 2097152 个字节
net.core.wmem_max = 2097152                      # 套接字的发送缓存区的最大容量为 2097152 个字节

""""""""" 演示内核调优的基本步骤
[root ~]# cat > /etc/security/limits.conf << EOF
*  soft  nofile  65535
*  hard  nofile  65535
*  soft  nproc   65535
*  hard  nproc   65535
*  soft  stack   65535
*  hard  stack   65535
*  soft  memlock unlimited
*  hard  memlock unlimited
*  soft  core    -1
*  hard  core    -1
*  soft  rss     -1
*  hard  rss     -1
EOF
[root ~]# ulimit -a
--------------------------------------------------------------------------------------------------------------------- ✻

""""""""" 演示内核调优的基本步骤
[root ~]# cat > /etc/sysctl.conf << EOF
fs.file-max = 65535
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_keepalive_time = 600
net.ipv4.tcp_fin_timeout = 30
net.ipv4.tcp_max_tw_buckets = 5000
net.ipv4.tcp_syncookies = 1
net.ipv4.tcp_max_syn_backlog = 4096
net.ipv4.tcp_rmem = 4096 32768 262142
net.ipv4.tcp_wmem = 4096 32768 262142
net.ipv4.ip_local_port_range = 1024 65535
net.core.netdev_max_backlog = 8096
net.core.rmem_default = 262144
net.core.wmem_default = 262144
net.core.rmem_max = 2097152
net.core.wmem_max = 2097152
EOF
[root ~]# sysctl -p
--------------------------------------------------------------------------------------------------------------------- ✻



━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
ELK 项目的日志规范
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
ELK 项目用作日志数据处理项目时, 通常会提前约束日志数据的标准格式
ELK 项目建议的日志数据的标准格式定义如下:

    $(date +"%Y-%m-%d %H:%M:%S.%3N") ${LEVEL} [${FEATURE}] ${MESSAGE}
    =================================================================
    •  $(date +"%Y-%m-%d %H:%M:%S.%3N")          符合 ISO8601 标准的时间戳
    •  ${LEVEL}                                  使用大写字符的日志等级, 例如 DEBUG/ INFO/ WARN/ ERROR/ EMERG/ ...
    •  ${FEATURE}                                预留给日志使用的特征字段, 可以输出业务名称/ 方法名称/ 方法路径/ 执行结果/ ...
    •  ${MESSAGE}                                预留给日志使用的正文字段, 可以换行输出

┌─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│                                                                                                                     │
│   2021-03-05 11:57:15.111 DEBUG [Logger.__init__] This is debug demo                                                │
│   2021-03-05 11:57:16.111 INFO [Logger.info] This is info demo                                                      │
│   2021-03-05 11:57:17.111 WARN [Logger.warn] This is warn demo                                                      │
│   2021-03-05 11:57:18.111 ERROR [Logger.error] This is error demo                                                   │
│           at org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:448) ~[hadoop-common-2.8.0.jar:?]         │
│           at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:419) ~[hadoop-common-2.8.0.jar:?]              │
│           at org.apache.hadoop.util.Shell.<clinit>(Shell.java:496) [hadoop-common-2.8.0.jar:?]                      │
│           at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79) [hadoop-common-2.8.0.jar:?]           │
│           at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1445) [hadoop-common-2.8.0.jar:?]   │
│           at com.cherrish.hadoop.TestHBase2.init(TestHBase2.java:28) [bin/:?]                                       │
│           at com.cherrish.hadoop.TestHBase2.listTables(TestHBase2.java:107) [bin/:?]                                │
│           at com.cherrish.hadoop.TestHBase2.main(TestHBase2.java:17) [bin/:?]                                       │
│                                                                                                                     │
└─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘



