 , __                                                     
/|/  \                                    o               
 |___/ ,_    _    _   __,   ,_    __, _|_     __   _  _   
 |    /  |  |/  |/ \_/  |  /  |  /  |  |  |  /  \_/ |/ |  
 |       |_/|__/|__/ \_/|_/   |_/\_/|_/|_/|_/\__/   |  |_/
               /|                                         
               \|                                                                                                         
--  This document was created by Xuanming in 2023, thanks for your reading



━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Kafka 软件的发展历程
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Kafka 软件是互联网生态中最常见的消息发布订阅软件, 其中文译名 "卡夫卡" 是一个常见的德文译文名字, 致敬小说家 Franz Kafka (1883~1924)
Kafka 软件由领英公司 (LinkedIn) 的数据流开发团队最先发布, 目前由阿帕奇软件基金会 (Apache Software Foundation) 负责迭代与维护

Kafka 软件的发展历程清晰简单
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
**  2010 年, 领英公司的数据流开发团队使用 ActiveMQ 软件处理业务组件之间的消息传递, 但遭遇到日益显著的性能瓶颈
**  2011 年, 领英公司的数据流开发团队使用 Java/ Scala 语言编写出 Kafka 软件
**  2012 年, 领英公司把项目整体捐献给阿帕奇软件基金会
**  2014 年, 领英公司的数据流开发团队在旧金山创建溪流公司 (Confluent), 专门从事 Kafka 软件的开源和协作, 并对外提供商用付费服务
**  2017 年, 溪流公司与亚马逊云 (AWS)/ 微软云 (Azure)/ 谷歌云 (Google Cloud) 合作, 推出 SaaS 服务
**  2020 年, 溪流公司荣获大数据新闻网站的读者选择奖 (Datanami Reader's Choice Award)

┌────────────┬──────────┬─────────────────────────────────────────────────────────────────────────────────────────────┐
│            │          │ • Java 9                                                                                    │
│ 2017-11-01 │ 1.0.0    │ • TLS & CRC32C                                                                              │
│            │          │ • JBOD storage configure                                                                    │
├────────────┼──────────┼─────────────────────────────────────────────────────────────────────────────────────────────┤
│            │          │ • enable regex in sink connector                                                            │
│ 2018-03-28 │ 1.1.0    │ • broker update dynamically                                                                 │
│            │          │ • replica movement between some directories                                                 │
├────────────┼──────────┼─────────────────────────────────────────────────────────────────────────────────────────────┤
│            │          │ • dead letter queue                                                                         │
│ 2018-07-30 │ 2.0.0    │ • move secret out of connector configure                                                    │
│            │          │ • reduce out of memory error in broker                                                      │
├────────────┼──────────┼─────────────────────────────────────────────────────────────────────────────────────────────┤
│            │          │ • Java 11                                                                                   │
│ 2018-11-20 │ 2.1.0    │ • improved admin script and client                                                          │
│            │          │ • avoid expire offset                                                                       │
├────────────┼──────────┼─────────────────────────────────────────────────────────────────────────────────────────────┤
│            │          │ • SSL                                                                                       │
│ 2019-05-22 │ 2.2.0    │ • SASL connection                                                                           │
│            │          │ • improved consumer group management                                                        │
├────────────┼──────────┼─────────────────────────────────────────────────────────────────────────────────────────────┤
│            │          │ • incremental cooperative rebalance                                                         │
│ 2019-06-25 │ 2.3.0    │ • in-memory session storage                                                                 │
│            │          │ • track partition that is under min ISR count                                               │
├────────────┼──────────┼─────────────────────────────────────────────────────────────────────────────────────────────┤
│            │          │ • consumer fetch data from closest replica                                                  │
│ 2019-12-16 │ 2.4.0    │ • MM2 engine                                                                                │
│            │          │ • support non-key joining                                                                   │
├────────────┼──────────┼─────────────────────────────────────────────────────────────────────────────────────────────┤
│            │          │ • TLS 1.3                                                                                   │
│ 2020-04-15 │ 2.5.0    │ • incremental rebalance for consumer                                                        │
│            │          │ • co-group for streams                                                                      │
├────────────┼──────────┼─────────────────────────────────────────────────────────────────────────────────────────────┤
│            │          │ • improved significant performance                                                          │
│ 2020-08-03 │ 2.6.0    │ • improved error reporting options for sink connector                                       │
│            │          │ • create topic automatically                                                                │
├────────────┼──────────┼─────────────────────────────────────────────────────────────────────────────────────────────┤
│            │          │ • TCP connection configure                                                                  │
│ 2020-12-21 │ 2.7.0    │ • PEM format for SSL                                                                        │
│            │          │ • add sliding-window support for aggregations                                               │
├────────────┼──────────┼─────────────────────────────────────────────────────────────────────────────────────────────┤
│            │          │ • JSON request & response debug log                                                         │
│ 2021-04-19 │ 2.8.0    │ • limit broker connection creation rate                                                     │
│            │          │ • KRaft metadata mode                                                                       │
├────────────┼──────────┼─────────────────────────────────────────────────────────────────────────────────────────────┤
│            │          │ • snapshot for metadata topic                                                               │
│ 2021-09-21 │ 3.0.0    │ • deprecation of message formats v0 & v1                                                    │
│            │          │ • enhanced semantics for timestamp synchronization                                          │
├────────────┼──────────┼─────────────────────────────────────────────────────────────────────────────────────────────┤
│            │          │ • SASL for OIDC                                                                             │
│ 2022-01-24 │ 3.1.0    │ • add broker count metrics                                                                  │
│            │          │ • range queries with open endpoints                                                         │
├────────────┼──────────┼─────────────────────────────────────────────────────────────────────────────────────────────┤
│            │          │ • connect source task handle producer exceptions                                            │
│ 2022-05-17 │ 3.2.0    │ • rack-aware standby task assignment                                                        │
│            │          │ • send a hint to the partition leader to recover the partiton                               │
├────────────┼──────────┼─────────────────────────────────────────────────────────────────────────────────────────────┤
│            │          │ • atomic commit fo source connector records and offsets                                     │
│ 2022-08-29 │ 3.3.0    │ • add metric for log recovery progress                                                      │
│            │          │ • admin API                                                                                 │
└────────────┴──────────┴─────────────────────────────────────────────────────────────────────────────────────────────┘

Kafka 软件的官方网站与 GitHub 第三方开源社区, 清华大学开源软件镜像站等都提供相应软件的下载服务
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
当前文档的演示案例统一使用 Kafka 3.3.2/ ZooKeeper 3.8.0/ OpenJDK 1.8.0 版本, 其下载地址为:

    •  Kafka                                     [                                 https://kafka.apache.org/downloads ]
    •  Kafka                                     [                               https://github.com/apache/kafka/tags ]
    •  Kafka-UI                                  [                         https://github.com/provectus/kafka-ui/tags ]
    •  ZooKeeper                                 [                         https://zookeeper.apache.org/releases.html ]
    •  ZooKeeper                                 [                           https://github.com/apache/zookeeper/tags ]
    •  OpenJDK                                   [                                https://github.com/openjdk/jdk/tags ]
    •  ORACLE JDK                                [                    https://download.oracle.com/java/17/archive/... ]



━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Kafka 软件的安装过程 (使用分布式协调软件)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Kafka 软件可以使用 ZooKeeper 软件协调自身的分布式集群
Kafka 软件已经内置 ZooKeeper 软件的运行程序, 但人们在正规的业务环境下更倾向于单独部署一套高可用的 ZooKeeper 软件

Kafka 软件如果使用二进制软件包安装, 可以得到下述文件
┌────────────────────────────────────────────────┬─────┬───────────────────────────────────────────────────────────────
│ Path                                           │ F/D │ Comment
├────────────────────────────────────────────────┼─────┼───────────────────────────────────────────────────────────────
│ /path/to/kafka                                 │  D  │ 软件的安装目录
│ /path/to/kafka/bin                             │  D  │ 软件的执行目录
│ /path/to/kafka/libs                            │  D  │ 软件的库文件目录
│ /path/to/kafka/config                          │  D  │ 软件的配置目录
│ /path/to/kafka/logs                            │  D  │ 软件默认使用的日志目录
│ /tmp/kafka-logs                                │  D  │ 软件默认使用的数据目录
│ /path/to/kafka/bin/kafka-server-start.sh       │  F  │ 软件的服务启动脚本, 能够调整软件的 JVM 启动参数
│ /path/to/kafka/bin/kafka-server-stop.sh        │  F  │ 软件的服务关闭脚本
│ /path/to/kafka/config/server.properties        │  F  │ 软件的主配置文件
│ /path/to/kafka/config/log4j.properties         │  F  │ 软件的 Log4j 日志参数配置文件
│ /path/to/kafka/logs/server.log                 │  F  │ 软件默认使用的服务器端日志
│ /path/to/kafka/logs/state-change.log           │  F  │ 软件默认使用的节点状态变化日志
│ /path/to/kafka/logs/kafka-request.log          │  F  │ 软件默认使用的节点请求处理日志
│ /path/to/kafka/logs/log-cleaner.log            │  F  │ 软件默认使用的数据清理日志
│ /path/to/kafka/logs/controller.log             │  F  │ 软件默认使用的管理日志
│ /path/to/kafka/logs/kafka-authorizer.log       │  F  │ 软件默认使用的用户认证日志
│ /tmp/kafka-logs/cleaner-offset-checkpoint      │  F  │ 软件默认使用的元数据文件, 记录业务数据的结束偏移量
│ /tmp/kafka-logs/log-start-offset-checkpoint    │  F  │ 软件默认使用的元数据文件, 记录业务数据的起始偏移量
│ /tmp/kafka-logs/meta.properties                │  F  │ 软件默认使用的元数据文件, 记录节点本身的元数据
│ /tmp/kafka-logs/recovery-point-offset-checkp...│  F  │ 软件默认使用的元数据文件, 记录磁盘文件的检查点元数据 (LEO)
│ /tmp/kafka-logs/replication-offset-checkpoint  │  F  │ 软件默认使用的元数据文件, 记录副本文件的偏移量元数据 (HW)
└────────────────────────────────────────────────┴─────┴───────────────────────────────────────────────────────────────

Kafka 软件如果按照演示文档的步骤部署, 可以得到下述文件
┌────────────────────────────────────────────────┬─────┬───────────────────────────────────────────────────────────────
│ Path                                           │ F/D │ Comment
├────────────────────────────────────────────────┼─────┼───────────────────────────────────────────────────────────────
│ /usr/local/kafka                               │  D  │ 软件的安装目录
│ /usr/local/kafka/bin                           │  D  │ 软件的执行目录
│ /usr/local/kafka/libs                          │  D  │ 软件的库文件目录
│ /etc/kafka                                     │  D  │ 软件的配置目录
│ /var/log/kafka                                 │  D  │ 软件的日志目录
│ /var/kafka/data                                │  D  │ 软件的数据目录
│ /etc/init.d/kafka                              │  F  │ 软件的 Initd (RHEL6) 风格的服务单元管理文件
│ /usr/lib/systemd/system/kafka.service          │  F  │ 软件的 Systemd (RHEL7) 风格的服务单元管理文件
│ /usr/local/kafka/bin/kafka-server-start.sh     │  F  │ 软件的服务启动脚本, 能够调整软件的 JVM 启动参数
│ /usr/local/kafka/bin/kafka-server-stop.sh      │  F  │ 软件的服务关闭脚本
│ /etc/kafka/server.properties                   │  F  │ 软件的主配置文件
│ /etc/kafka/log4j.properties                    │  F  │ 软件的 Log4j 日志参数配置文件
│ /var/log/kafka/server.log                      │  F  │ 软件的服务器端日志
│ /var/log/kafka/state-change.log                │  F  │ 软件的节点状态变化日志
│ /var/log/kafka/kafka-request.log               │  F  │ 软件的节点请求处理日志
│ /var/log/kafka/log-cleaner.log                 │  F  │ 软件的数据清理日志
│ /var/log/kafka/controller.log                  │  F  │ 软件的管理日志
│ /var/log/kafka/kafka-authorizer.log            │  F  │ 软件的用户认证日志
│ /var/kafka/data/cleaner-offset-checkpoint      │  F  │ 软件的元数据文件, 记录业务数据的结束偏移量
│ /var/kafka/data/log-start-offset-checkpoint    │  F  │ 软件的元数据文件, 记录业务数据的起始偏移量
│ /var/kafka/data/meta.properties                │  F  │ 软件的元数据文件, 记录节点本身的元数据
│ /var/kafka/data/recovery-point-offset-checkp...│  F  │ 软件的元数据文件, 记录磁盘文件的检查点元数据 (LEO)
│ /var/kafka/data/replication-offset-checkpoint  │  F  │ 软件的元数据文件, 记录副本文件的偏移量元数据 (HW)
└────────────────────────────────────────────────┴─────┴───────────────────────────────────────────────────────────────

""""""""" 准备软件的运行环境
[root ~]# useradd -r -s /sbin/nologin -M kafka
[root ~]# mkdir -p /usr/local/kafka /var/log/kafka /var/kafka/data /etc/kafka
[root ~]# chown -R kafka:kafka /usr/local/kafka /var/log/kafka /var/kafka
[root ~]# sudo -u kafka tar -xzf /srv/kafka_2.13-3.3.2.tgz -C /usr/local/kafka --strip-components 1
[root ~]# cp /usr/local/kafka/config/{server.properties,log4j.properties} /etc/kafka
--------------------------------------------------------------------------------------------------------------------- ✻

""""""""" 更新软件的配置文件并启动服务
[root ~]# vim /etc/kafka/server.properties
[root ~]# vim /etc/kafka/log4j.properties
[root ~]# sed -i.bakp -r '/-Dlog4j\.configuration/s/^(.*)(file:)(.*)(\")$/\1\2\/etc\/kafka\/log4j.properties\4/g' \
/usr/local/kafka/bin/connect-distributed.sh \
/usr/local/kafka/bin/connect-mirror-maker.sh \
/usr/local/kafka/bin/connect-standalone.sh \
/usr/local/kafka/bin/kafka-run-class.sh \
/usr/local/kafka/bin/kafka-server-start.sh \
/usr/local/kafka/bin/zookeeper-server-start.sh
[root ~]# sed -i -r '/^exec/i\export JMX_PORT=9094' /usr/local/kafka/bin/kafka-server-start.sh
[root ~]# vim /usr/lib/systemd/system/kafka.service
[root ~]# vim /etc/init.d/kafka
[root ~]# systemctl daemon-reload
[root ~]# systemctl enable kafka.service
[root ~]# systemctl start kafka.service
--------------------------------------------------------------------------------------------------------------------- ✻



━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Kafka 软件的安装过程 (使用 KRaft 元数据模式)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Kafka 软件可以使用 KRaft 元数据模式协调自身的分布式集群
Kafka 软件目前认为 KRaft 元数据模式的成熟度不足以达到生产环境的稳定性要求, 生产环境谨慎使用 KRaft 元数据模式

注意: $(/usr/local/kafka/bin/kafka-storage.sh random-uuid) 命令制作的随机码应当被集群的全部节点使用且保持不变

""""""""" 准备软件的运行环境
[root ~]# useradd -r -s /sbin/nologin -M kafka
[root ~]# mkdir -p /usr/local/kafka /var/log/kafka /var/kafka/{data,metadata} /etc/kafka/kraft
[root ~]# chown -R kafka:kafka /usr/local/kafka /var/log/kafka /var/kafka
[root ~]# sudo -u kafka tar -xzf /srv/kafka_2.13-3.3.2.tgz -C /usr/local/kafka --strip-components 1
[root ~]# cp /usr/local/kafka/config/log4j.properties /etc/kafka
[root ~]# cp /usr/local/kafka/config/kraft/server.properties /etc/kafka/kraft
--------------------------------------------------------------------------------------------------------------------- ✻

""""""""" 更新软件的配置文件
[root ~]# vim /etc/kafka/kraft/server.properties
[root ~]# vim /etc/kafka/log4j.properties
[root ~]# sed -i.bakp -r '/-Dlog4j\.configuration/s/^(.*)(file:)(.*)(\")$/\1\2\/etc\/kafka\/log4j.properties\4/g' \
/usr/local/kafka/bin/connect-distributed.sh \
/usr/local/kafka/bin/connect-mirror-maker.sh \
/usr/local/kafka/bin/connect-standalone.sh \
/usr/local/kafka/bin/kafka-run-class.sh \
/usr/local/kafka/bin/kafka-server-start.sh \
/usr/local/kafka/bin/zookeeper-server-start.sh
[root ~]# sed -i -r '/^exec/i\export JMX_PORT=9094' /usr/local/kafka/bin/kafka-server-start.sh
[root ~]# /usr/local/kafka/bin/kafka-storage.sh random-uuid

VW3aScTKQTWJeBkZtcJHRQ

[root ~]# /usr/local/kafka/bin/kafka-storage.sh format \
-t VW3aScTKQTWJeBkZtcJHRQ \
-c /etc/kafka/kraft/server.properties

Formatting /var/kafka/data with metadata.version 3.3-IV3
Formatting /var/kafka/metadata with metadata.version 3.3-IV3
--------------------------------------------------------------------------------------------------------------------- ✻

""""""""" 使用 KRaft 元数据模式启动服务
[root ~]# vim /usr/lib/systemd/system/kafka-kraft.service
[root ~]# vim /etc/init.d/kafka-kraft
[root ~]# systemctl daemon-reload
[root ~]# systemctl enable kafka-kraft.service
[root ~]# systemctl start kafka-kraft.service
[root ~]# tree /var/kafka/metadata/__cluster_metadata-0

/var/kafka/metadata/__cluster_metadata-0
│
├─── 00000000000000000000.index
├─── 00000000000000000000.log
├─── 00000000000000000000.timeindex
├─── leader-epoch-checkpoint
├─── partition.metadata
└─── quorum-state
--------------------------------------------------------------------------------------------------------------------- ✻



