 , __                                                     
/|/  \                                    o               
 |___/ ,_    _    _   __,   ,_    __, _|_     __   _  _   
 |    /  |  |/  |/ \_/  |  /  |  /  |  |  |  /  \_/ |/ |  
 |       |_/|__/|__/ \_/|_/   |_/\_/|_/|_/|_/\__/   |  |_/
               /|                                         
               \|                                                                                                         
--  This document was created by Xuanming in 2023, thanks for your reading



━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Kafka 软件的发展历程
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Kafka 软件是互联网生态中最常见的消息发布订阅软件, 其中文译名 "卡夫卡" 是一个常见的德文译文名字, 致敬小说家 Franz Kafka (1883~1924)
Kafka 软件由领英公司 (LinkedIn) 的数据流开发团队最先发布, 目前由阿帕奇软件基金会 (Apache Software Foundation) 负责迭代与维护

Kafka 软件的发展历程清晰简单
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
**  2010 年, 领英公司的数据流开发团队使用 ActiveMQ 软件处理业务组件之间的消息传递, 但遭遇到日益显著的性能瓶颈
**  2011 年, 领英公司的数据流开发团队使用 Java/ Scala 语言编写出 Kafka 软件
**  2012 年, 领英公司把项目整体捐献给阿帕奇软件基金会
**  2014 年, 领英公司的数据流开发团队在旧金山创建溪流公司 (Confluent), 专门从事 Kafka 软件的开源和协作, 并对外提供商用付费服务
**  2017 年, 溪流公司与亚马逊云 (AWS)/ 微软云 (Azure)/ 谷歌云 (Google Cloud) 合作, 推出 SaaS 服务
**  2020 年, 溪流公司荣获大数据新闻网站的读者选择奖 (Datanami Reader's Choice Award)

┌────────────┬──────────┬─────────────────────────────────────────────────────────────────────────────────────────────┐
│            │          │ • Java 9                                                                                    │
│ 2017-11-01 │ 1.0.0    │ • TLS & CRC32C                                                                              │
│            │          │ • JBOD storage configure                                                                    │
├────────────┼──────────┼─────────────────────────────────────────────────────────────────────────────────────────────┤
│            │          │ • enable regex in sink connector                                                            │
│ 2018-03-28 │ 1.1.0    │ • broker update dynamically                                                                 │
│            │          │ • replica movement between some directories                                                 │
├────────────┼──────────┼─────────────────────────────────────────────────────────────────────────────────────────────┤
│            │          │ • dead letter queue                                                                         │
│ 2018-07-30 │ 2.0.0    │ • move secret out of connector configure                                                    │
│            │          │ • reduce out of memory error in broker                                                      │
├────────────┼──────────┼─────────────────────────────────────────────────────────────────────────────────────────────┤
│            │          │ • Java 11                                                                                   │
│ 2018-11-20 │ 2.1.0    │ • improved admin script and client                                                          │
│            │          │ • avoid expire offset                                                                       │
├────────────┼──────────┼─────────────────────────────────────────────────────────────────────────────────────────────┤
│            │          │ • SSL                                                                                       │
│ 2019-05-22 │ 2.2.0    │ • SASL connection                                                                           │
│            │          │ • improved consumer group management                                                        │
├────────────┼──────────┼─────────────────────────────────────────────────────────────────────────────────────────────┤
│            │          │ • incremental cooperative rebalance                                                         │
│ 2019-06-25 │ 2.3.0    │ • in-memory session storage                                                                 │
│            │          │ • track partition that is under min ISR count                                               │
├────────────┼──────────┼─────────────────────────────────────────────────────────────────────────────────────────────┤
│            │          │ • consumer fetch data from closest replica                                                  │
│ 2019-12-16 │ 2.4.0    │ • MM2 engine                                                                                │
│            │          │ • support non-key joining                                                                   │
├────────────┼──────────┼─────────────────────────────────────────────────────────────────────────────────────────────┤
│            │          │ • TLS 1.3                                                                                   │
│ 2020-04-15 │ 2.5.0    │ • incremental rebalance for consumer                                                        │
│            │          │ • co-group for streams                                                                      │
├────────────┼──────────┼─────────────────────────────────────────────────────────────────────────────────────────────┤
│            │          │ • improved significant performance                                                          │
│ 2020-08-03 │ 2.6.0    │ • improved error reporting options for sink connector                                       │
│            │          │ • create topic automatically                                                                │
├────────────┼──────────┼─────────────────────────────────────────────────────────────────────────────────────────────┤
│            │          │ • TCP connection configure                                                                  │
│ 2020-12-21 │ 2.7.0    │ • PEM format for SSL                                                                        │
│            │          │ • add sliding-window support for aggregations                                               │
├────────────┼──────────┼─────────────────────────────────────────────────────────────────────────────────────────────┤
│            │          │ • Json request & response debug log                                                         │
│ 2021-04-19 │ 2.8.0    │ • limit broker connection creation rate                                                     │
│            │          │ • KRaft metadata mode                                                                       │
├────────────┼──────────┼─────────────────────────────────────────────────────────────────────────────────────────────┤
│            │          │ • snapshot for metadata topic                                                               │
│ 2021-09-21 │ 3.0.0    │ • deprecation of message formats v0 & v1                                                    │
│            │          │ • enhanced semantics for timestamp synchronization                                          │
├────────────┼──────────┼─────────────────────────────────────────────────────────────────────────────────────────────┤
│            │          │ • SASL for OIDC                                                                             │
│ 2022-01-24 │ 3.1.0    │ • add broker count metrics                                                                  │
│            │          │ • range queries with open endpoints                                                         │
├────────────┼──────────┼─────────────────────────────────────────────────────────────────────────────────────────────┤
│            │          │ • connect source task handle producer exceptions                                            │
│ 2022-05-17 │ 3.2.0    │ • rack-aware standby task assignment                                                        │
│            │          │ • send a hint to the partition leader to recover the partiton                               │
├────────────┼──────────┼─────────────────────────────────────────────────────────────────────────────────────────────┤
│            │          │ • atomic commit fo source connector records and offsets                                     │
│ 2022-08-29 │ 3.3.0    │ • add metric for log recovery progress                                                      │
│            │          │ • admin API                                                                                 │
└────────────┴──────────┴─────────────────────────────────────────────────────────────────────────────────────────────┘

Kafka 软件的官方网站与 GitHub 第三方开源社区, 清华大学开源软件镜像站等都提供相应软件的下载服务
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
当前文档的演示案例统一使用 Kafka 3.3.2/ ZooKeeper 3.8.0/ OpenJDK 1.8.0 版本, 其下载地址为:

    •  Kafka                                     [                                 https://kafka.apache.org/downloads ]
    •  Kafka                                     [                               https://github.com/apache/kafka/tags ]
    •  Kafka-UI                                  [                         https://github.com/provectus/kafka-ui/tags ]
    •  ZooKeeper                                 [                         https://zookeeper.apache.org/releases.html ]
    •  ZooKeeper                                 [                           https://github.com/apache/zookeeper/tags ]
    •  OpenJDK                                   [                                https://github.com/openjdk/jdk/tags ]



━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Kafka 软件的主机配置
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Kafka 软件受主机的内核参数的影响, 这些内核参数登记在下述配置文件:

    •  资源限制文件 /etc/security/limits.conf
    •  资源限制文件 /etc/security/limits.d/20-nproc.conf (优先级高于 /etc/security/limits.conf 资源限制文件)
    •  内核参数文件 /etc/sysctl.conf

资源限制文件 /etc/security/limits.conf
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*  soft  nofile  65535                           # 任意用户允许打开的文件句柄数量 (若触发阈值则告警)
*  hard  nofile  65535                           # 任意用户允许打开的文件句柄数量 (若触发阈值则不允许创建新的文件句柄)
*  soft  nproc   65535                           # 任意用户允许打开的进程数量 (若触发阈值则告警)
*  hard  nproc   65535                           # 任意用户允许打开的进程数量 (若触发阈值则不允许创建新的进程)
*  soft  stack   65535                           # 内存栈的容量上限, 容量单位 KB (若触发阈值则告警)
*  hard  stack   65535                           # 内存栈的容量上限, 容量单位 KB (若触发阈值则不允许继续扩大内存栈的容量)
*  soft  memlock unlimited                       # 允许用户锁定内存资源, 被锁定的内存资源不设置容量上限
*  hard  memlock unlimited                       # 允许用户锁定内存资源, 被锁定的内存资源不设置容量上限
*  soft  core    -1                              # 不设 coredump 文件的容量上限, 容量单位 KB
*  hard  core    -1                              # 不设 coredump 文件的容量上限, 容量单位 KB
*  soft  rss     -1
*  hard  rss     -1

内核参数文件 /etc/sysctl.conf
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
fs.file-max = 65535                              # 单个进程允许打开的文件句柄数量
net.ipv4.tcp_tw_reuse = 1                        # 新的连接允许复用 TIME_WAIT 状态下的套接字 (缩短套接字的释放时间)
net.ipv4.tcp_keepalive_time = 600                # 会话保持的探测频率为 600 秒
net.ipv4.tcp_fin_timeout = 30                    # 套接字保持 FIN_WAIT2 状态的时间上限为 30 秒
net.ipv4.tcp_max_tw_buckets = 5000               # 套接字保持 TIME_WAIT 状态的数量上限为 5000 个套接字 (多余套接字直接被清理)
net.ipv4.tcp_syncookies = 1                      # 避免主机遭受 TCP 连接的 SYN 攻击
net.ipv4.tcp_max_syn_backlog = 4096              # 配置连接的 SYN 请求队列的长度为 4096 (避免主机丢失客户端的连接请求)
net.ipv4.tcp_rmem = 4096 32768 262142            # 配置连接的接收缓存的最小值/ 默认值/ 最大值 (单位: 字节)
net.ipv4.tcp_wmem = 4096 32768 262142            # 配置连接的发送缓存的最小值/ 默认值/ 最大值 (单位: 字节)
net.ipv4.ip_local_port_range = 1024 65535        # 配置连接的本地端口的取值范围
net.core.netdev_max_backlog = 8096               # 配置连接的冗余接收队列的长度为 8096 个请求
net.core.rmem_default = 262144                   # 套接字的接收缓存区的默认容量为 262144 个字节
net.core.wmem_default = 262144                   # 套接字的发送缓存区的默认容量为 262144 个字节
net.core.rmem_max = 2097152                      # 套接字的接收缓存区的最大容量为 2097152 个字节
net.core.wmem_max = 2097152                      # 套接字的发送缓存区的最大容量为 2097152 个字节

""""""""" 演示内核调优的基本步骤
[root ~]# cat > /etc/security/limits.conf << EOF
*  soft  nofile  65535
*  hard  nofile  65535
*  soft  nproc   65535
*  hard  nproc   65535
*  soft  stack   65535
*  hard  stack   65535
*  soft  memlock unlimited
*  hard  memlock unlimited
*  soft  core    -1
*  hard  core    -1
*  soft  rss     -1
*  hard  rss     -1
EOF
[root ~]# ulimit -a
--------------------------------------------------------------------------------------------------------------------- ✻

""""""""" 演示内核调优的基本步骤
[root ~]# cat > /etc/sysctl.conf << EOF
fs.file-max = 65535
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_keepalive_time = 600
net.ipv4.tcp_fin_timeout = 30
net.ipv4.tcp_max_tw_buckets = 5000
net.ipv4.tcp_syncookies = 1
net.ipv4.tcp_window_scaling = 1
net.ipv4.tcp_max_syn_backlog = 4096
net.ipv4.tcp_rmem = 4096 32768 262142
net.ipv4.tcp_wmem = 4096 32768 262142
net.ipv4.ip_local_port_range = 1024 65535
net.core.netdev_max_backlog = 8096
net.core.rmem_default = 262144
net.core.wmem_default = 262144
net.core.rmem_max = 2097152
net.core.wmem_max = 2097152
vm.dirty_ratio = 60
EOF
[root ~]# sysctl -p
--------------------------------------------------------------------------------------------------------------------- ✻



━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Kafka 软件的安装过程
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Kafka 软件支持使用二进制软件包安装, 二进制软件包的 TGZ 压缩包可以基于 GitHub/ Apache 社区站点下载
Kafka 软件内置 ZooKeeper 软件的运行程序, 但在正规的业务环境下, 人们更倾向于单独部署一套高可用的 ZooKeeper 软件

Kafka 软件如果使用二进制软件包安装, 可以得到下述文件
┌────────────────────────────────────────────────┬─────┬───────────────────────────────────────────────────────────────
│ Path                                           │ F/D │ Comment
├────────────────────────────────────────────────┼─────┼───────────────────────────────────────────────────────────────
│ /usr/local/kafka                               │  D  │ 软件的安装目录
│ /usr/local/kafka/bin                           │  D  │ 软件的执行目录
│ /usr/local/kafka/libs                          │  D  │ 软件的库文件目录
│ /usr/local/kafka/config                        │  D  │ 软件的配置目录
│ /usr/local/kafka/config/kraft                  │  D  │ 软件的配置目录 (使用 KRaft 元数据模式)
│ /usr/local/kafka/logs                          │  D  │ 软件默认使用的日志目录
│ /tmp/kafka-logs                                │  D  │ 软件默认使用的数据目录
│ /usr/local/kafka/bin/kafka-server-start.sh     │  F  │ 软件的服务启动脚本, 能够调整软件的 JVM 启动参数
│ /usr/local/kafka/bin/kafka-server-stop.sh      │  F  │ 软件的服务关闭脚本
│ /usr/local/kafka/config/server.properties      │  F  │ 软件的主配置文件
│ /usr/local/kafka/config/log4j.properties       │  F  │ 软件的 Log4j 日志参数配置文件
│ /usr/local/kafka/logs/server.log               │  F  │ 软件默认使用的服务器端日志
│ /usr/local/kafka/logs/state-change.log         │  F  │ 软件默认使用的节点状态变化日志
│ /usr/local/kafka/logs/kafka-request.log        │  F  │ 软件默认使用的节点请求处理日志
│ /usr/local/kafka/logs/log-cleaner.log          │  F  │ 软件默认使用的数据清理日志
│ /usr/local/kafka/logs/controller.log           │  F  │ 软件默认使用的管理日志
│ /usr/local/kafka/logs/kafka-authorizer.log     │  F  │ 软件默认使用的用户认证日志
│ /tmp/kafka-logs/cleaner-offset-checkpoint      │  F  │ 软件默认使用的元数据文件, 记录业务数据的结束偏移量
│ /tmp/kafka-logs/log-start-offset-checkpoint    │  F  │ 软件默认使用的元数据文件, 记录业务数据的起始偏移量
│ /tmp/kafka-logs/meta.properties                │  F  │ 软件默认使用的元数据文件, 记录节点本身的元数据
│ /tmp/kafka-logs/recovery-point-offset-checkp...│  F  │ 软件默认使用的元数据文件, 记录磁盘文件的检查点元数据 (LEO)
│ /tmp/kafka-logs/replication-offset-checkpoint  │  F  │ 软件默认使用的元数据文件, 记录副本文件的偏移量元数据 (HW)
└────────────────────────────────────────────────┴─────┴───────────────────────────────────────────────────────────────

Kafka 软件如果按照演示文档的步骤部署, 可以得到下述文件
┌────────────────────────────────────────────────┬─────┬───────────────────────────────────────────────────────────────
│ Path                                           │ F/D │ Comment
├────────────────────────────────────────────────┼─────┼───────────────────────────────────────────────────────────────
│ /usr/local/kafka                               │  D  │ 软件的安装目录
│ /usr/local/kafka/bin                           │  D  │ 软件的执行目录
│ /usr/local/kafka/libs                          │  D  │ 软件的库文件目录
│ /etc/kafka                                     │  D  │ 软件的配置目录
│ /etc/kafka/kraft                               │  D  │ 软件的配置目录 (使用 KRaft 元数据模式)
│ /var/log/kafka                                 │  D  │ 软件的日志目录
│ /var/kafka/data                                │  D  │ 软件的数据目录
│ /var/kafka/metadata                            │  D  │ 软件的元数据目录 (使用 KRaft 元数据模式)
│ /etc/init.d/kafka                              │  F  │ 软件的 Initd (RHEL6) 风格的服务单元管理文件
│ /usr/lib/systemd/system/kafka.service          │  F  │ 软件的 Systemd (RHEL7) 风格的服务单元管理文件
│ /usr/local/kafka/bin/kafka-server-start.sh     │  F  │ 软件的服务启动脚本, 能够调整软件的 JVM 启动参数
│ /usr/local/kafka/bin/kafka-server-stop.sh      │  F  │ 软件的服务关闭脚本
│ /etc/kafka/server.properties                   │  F  │ 软件的主配置文件
│ /etc/kafka/kraft/server.properties             │  F  │ 软件的主配置文件 (使用 KRaft 元数据模式)
│ /etc/kafka/log4j.properties                    │  F  │ 软件的 Log4j 日志参数配置文件
│ /var/log/kafka/server.log                      │  F  │ 软件的服务器端日志
│ /var/log/kafka/state-change.log                │  F  │ 软件的节点状态变化日志
│ /var/log/kafka/kafka-request.log               │  F  │ 软件的节点请求处理日志
│ /var/log/kafka/log-cleaner.log                 │  F  │ 软件的数据清理日志
│ /var/log/kafka/controller.log                  │  F  │ 软件的管理日志
│ /var/log/kafka/kafka-authorizer.log            │  F  │ 软件的用户认证日志
│ /var/kafka/data/cleaner-offset-checkpoint      │  F  │ 软件的元数据文件, 记录业务数据的结束偏移量
│ /var/kafka/data/log-start-offset-checkpoint    │  F  │ 软件的元数据文件, 记录业务数据的起始偏移量
│ /var/kafka/data/meta.properties                │  F  │ 软件的元数据文件, 记录节点本身的元数据
│ /var/kafka/data/recovery-point-offset-checkp...│  F  │ 软件的元数据文件, 记录磁盘文件的检查点元数据 (LEO)
│ /var/kafka/data/replication-offset-checkpoint  │  F  │ 软件的元数据文件, 记录副本文件的偏移量元数据 (HW)
└────────────────────────────────────────────────┴─────┴───────────────────────────────────────────────────────────────

""""""""" 准备软件的运行环境
[root ~]# useradd -r -s /sbin/nologin -M kafka
[root ~]# mkdir -p /usr/local/kafka /var/log/kafka /var/kafka/{data,metadata} /etc/kafka/kraft
[root ~]# chown -R kafka:kafka /usr/local/kafka /var/log/kafka /var/kafka
[root ~]# sudo -u kafka tar -xzf /srv/kafka_2.13-3.3.2.tgz -C /usr/local/kafka --strip-components 1
[root ~]# cp /usr/local/kafka/config/{server.properties,log4j.properties} /etc/kafka
[root ~]# cp /usr/local/kafka/config/kraft/server.properties /etc/kafka/kraft
--------------------------------------------------------------------------------------------------------------------- ✻

""""""""" 更新软件的配置文件并启动服务
[root ~]# vim /etc/kafka/server.properties
[root ~]# vim /etc/kafka/log4j.properties
[root ~]# sed -i.bakp -r '/-Dlog4j\.configuration/s/^(.*)(file:)(.*)(\")$/\1\2\/etc\/kafka\/log4j.properties\4/g' \
/usr/local/kafka/bin/connect-distributed.sh \
/usr/local/kafka/bin/connect-mirror-maker.sh \
/usr/local/kafka/bin/connect-standalone.sh \
/usr/local/kafka/bin/kafka-run-class.sh \
/usr/local/kafka/bin/kafka-server-start.sh \
/usr/local/kafka/bin/zookeeper-server-start.sh
[root ~]# vim /usr/lib/systemd/system/kafka.service
[root ~]# vim /etc/init.d/kafka
[root ~]# systemctl daemon-reload
[root ~]# systemctl enable kafka.service
[root ~]# systemctl start kafka.service
--------------------------------------------------------------------------------------------------------------------- ✻



